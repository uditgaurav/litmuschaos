Important Commands 
--------------------

Installing / upgrading anisble on a cluster 
--------------------------------------------------
yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
sed -i -e "s/^enabled=1/enabled=0/" /etc/yum.repos.d/epel.repo
yum -y --enablerepo=epel install ansible pyOpenSSL


TO create Service Account on a Namespace
--------------------------------------------------
oc adm policy add-scc-to-user anyuid system:serviceaccount:percona1:default

litmus/chaos -Image used
--------------------------------------------------
image: openebs/ansible-runner:ci

git commands
git checkout -b udit upstream/generic-staging --track

Delete namespace when it stuck in terminating: https://github.com/kubernetes/kubernetes/issues/60807#issuecomment-408599873

sudo -H pip install --upgrade ansible

udit-ThinkPad-E490

Naag Raaj
6362244512


------
visudo
------
gitlab-runner ALL=(ALL) NOPASSWD: ALL

PROJECT - 2
--------------------
1. sed-command : 
          
sed 's/cpu: 500m/cpu: 300m/' test.yaml


2. To Edit Deployment
-------------------- 

kubectl patch deployment.v1.apps/percona -n percona1 -p '{"spec":{"template":{"spec":{"containers":[{"name":"percona","resources":{"limits":{"cpu":"500m" }}}]}}}}'

kubectl exec -it my-pod --container main-app -- /bin/bash



kubectl exec -it my-pod --container main-app -- /bin/bash



3. To enter into a container 
kubectl exec -it my-pod --container main-app -- /bin/bash

Fench CPU Request
kubectl describe nodes | grep -A 2 -e "^\\s*CPU Requests"



kubectl get po -n percona1 -o=jsonpath="{range .items[*]}{.metadata.namespace}:{.metadata.name}{'\n'}{range .spec.containers[*]}  {.name}:{.resources.requests.cpu}{'\n'}{end}{'\n'}{end}"



http://jmespath.org/


kubectl describe nodes node1-1558702621.mayalabs.io | grep -A 2 -e "^\\s*CPU Requests" | awk {'print $1'} | tail -n1


kubectl describe nodes node1-1558702621.mayalabs.io | grep -A 2 "CPU Limits" | awk '{print $3}' | tail -n1


gcloud compute instances attach-disk gke-standard-cluster-1-default-pool-0fee5f73-hr5n --device-name disk-1 --disk disk-1 --zone us-central1-a

